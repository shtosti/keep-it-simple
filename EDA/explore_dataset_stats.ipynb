{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newsela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade_level</th>\n",
       "      <th>version</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>flesh_reading_ease</th>\n",
       "      <th>difficult_words</th>\n",
       "      <th>type-token_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10786.000000</td>\n",
       "      <td>10786.000000</td>\n",
       "      <td>10786.000000</td>\n",
       "      <td>10786.000000</td>\n",
       "      <td>10786.000000</td>\n",
       "      <td>10786.000000</td>\n",
       "      <td>10786.000000</td>\n",
       "      <td>10786.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.019562</td>\n",
       "      <td>2.007973</td>\n",
       "      <td>923.379195</td>\n",
       "      <td>48.397923</td>\n",
       "      <td>4560.313369</td>\n",
       "      <td>68.707136</td>\n",
       "      <td>123.899777</td>\n",
       "      <td>0.448023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.996534</td>\n",
       "      <td>1.423471</td>\n",
       "      <td>326.257930</td>\n",
       "      <td>12.972465</td>\n",
       "      <td>1686.554274</td>\n",
       "      <td>12.292144</td>\n",
       "      <td>69.672704</td>\n",
       "      <td>0.037805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1075.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.193440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>3534.000000</td>\n",
       "      <td>61.060000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.424150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>4353.500000</td>\n",
       "      <td>69.620000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>0.447674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1074.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>5352.750000</td>\n",
       "      <td>76.930000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>0.471115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5241.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>26418.000000</td>\n",
       "      <td>105.860000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>0.625282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        grade_level       version    num_tokens  num_sentences  \\\n",
       "count  10786.000000  10786.000000  10786.000000   10786.000000   \n",
       "mean       7.019562      2.007973    923.379195      48.397923   \n",
       "std        2.996534      1.423471    326.257930      12.972465   \n",
       "min        2.000000      0.000000    244.000000      10.000000   \n",
       "25%        5.000000      1.000000    730.000000      41.000000   \n",
       "50%        7.000000      2.000000    884.000000      48.000000   \n",
       "75%        9.000000      3.000000   1074.000000      54.000000   \n",
       "max       12.000000      5.000000   5241.000000     169.000000   \n",
       "\n",
       "       num_characters  flesh_reading_ease  difficult_words  type-token_ratio  \n",
       "count    10786.000000        10786.000000     10786.000000      10786.000000  \n",
       "mean      4560.313369           68.707136       123.899777          0.448023  \n",
       "std       1686.554274           12.292144        69.672704          0.037805  \n",
       "min       1075.000000           17.000000         5.000000          0.193440  \n",
       "25%       3534.000000           61.060000        75.000000          0.424150  \n",
       "50%       4353.500000           69.620000       114.000000          0.447674  \n",
       "75%       5352.750000           76.930000       155.000000          0.471115  \n",
       "max      26418.000000          105.860000       750.000000          0.625282  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsela_df = pd.read_csv(\"newsela_with_analysis.csv\")\n",
    "newsela_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WikiLarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297753\n",
      "297753\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "BASE_PATH = \"./../../datasets/wiki/wikilarge\"\n",
    "BASE_FILENAME = f\"wiki.full.aner.ori.\"\n",
    "\n",
    "train_src_path = f\"{BASE_PATH}/{BASE_FILENAME}train.src\"\n",
    "train_dst_path = f\"{BASE_PATH}/{BASE_FILENAME}train.dst\"\n",
    "test_src_path = f\"{BASE_PATH}/{BASE_FILENAME}test.src\"\n",
    "test_dst_path = f\"{BASE_PATH}/{BASE_FILENAME}test.src\"\n",
    "valid_src_path = f\"{BASE_PATH}/{BASE_FILENAME}valid.src\"\n",
    "valid_dst_path = f\"{BASE_PATH}/{BASE_FILENAME}valid.dst\"\n",
    "\n",
    "\n",
    "with open(train_src_path, \"r\") as src, open(train_dst_path) as dst:\n",
    "    train_src = src.readlines()\n",
    "    train_dst = dst.readlines()\n",
    "with open(test_src_path, \"r\") as src, open(test_dst_path) as dst:\n",
    "    test_src = src.readlines()\n",
    "    test_dst = dst.readlines()\n",
    "with open(valid_src_path, \"r\") as src, open(valid_dst_path) as dst:\n",
    "    valid_src = src.readlines()\n",
    "    valid_dst = dst.readlines()\n",
    "\n",
    "# Create DataFrames for each split\n",
    "train_df = pd.DataFrame({\"source\": train_src, \"target\": train_dst, \"split\": \"train\"})\n",
    "test_df = pd.DataFrame({\"source\": test_src, \"target\": test_dst, \"split\": \"test\"})\n",
    "valid_df = pd.DataFrame({\"source\": valid_src, \"target\": valid_dst, \"split\": \"valid\"})\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "full_df = pd.concat([train_df, test_df, valid_df], ignore_index=True)\n",
    "print(len(full_df))\n",
    "full_df = full_df.drop_duplicates()\n",
    "print(len(full_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping duplicates: 297753\n",
      "After dropping duplicates: 297753\n",
      "                                              source  \\\n",
      "0  There is manuscript evidence that Austen conti...   \n",
      "1  In a remarkable comparative analysis , Mandaea...   \n",
      "2  Before Persephone was released to Hermes , who...   \n",
      "3  Cogeneration plants are commonly found in dist...   \n",
      "4  Geneva -LRB- , ; , ; , ; ; -RRB- is the second...   \n",
      "\n",
      "                                              target  split  \n",
      "0  There is some proof that Austen continued to w...  train  \n",
      "1  Mandaean scholar Säve-Söderberg showed that Ma...  train  \n",
      "2  When Demeter went to the Underworld to rescue ...  train  \n",
      "3  Cogeneration plants are commonly found in dist...  train  \n",
      "4  The city 's main newspaper is the Tribune de G...  train  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "BASE_PATH = \"./../../datasets/wiki/wikilarge\"\n",
    "BASE_FILENAME = f\"wiki.full.aner.ori.\"\n",
    "\n",
    "train_src_path = f\"{BASE_PATH}/{BASE_FILENAME}train.src\"\n",
    "train_dst_path = f\"{BASE_PATH}/{BASE_FILENAME}train.dst\"\n",
    "test_src_path = f\"{BASE_PATH}/{BASE_FILENAME}test.src\"\n",
    "test_dst_path = f\"{BASE_PATH}/{BASE_FILENAME}test.dst\"\n",
    "valid_src_path = f\"{BASE_PATH}/{BASE_FILENAME}valid.src\"\n",
    "valid_dst_path = f\"{BASE_PATH}/{BASE_FILENAME}valid.dst\"\n",
    "\n",
    "# Read the source and target files, and strip newline characters and extra spaces\n",
    "def read_and_clean(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        return [line.strip() for line in file.readlines()]\n",
    "\n",
    "train_src = read_and_clean(train_src_path)\n",
    "train_dst = read_and_clean(train_dst_path)\n",
    "test_src = read_and_clean(test_src_path)\n",
    "test_dst = read_and_clean(test_dst_path)\n",
    "valid_src = read_and_clean(valid_src_path)\n",
    "valid_dst = read_and_clean(valid_dst_path)\n",
    "\n",
    "# Create DataFrames for each split\n",
    "train_df = pd.DataFrame({\"source\": train_src, \"target\": train_dst, \"split\": \"train\"})\n",
    "test_df = pd.DataFrame({\"source\": test_src, \"target\": test_dst, \"split\": \"test\"})\n",
    "valid_df = pd.DataFrame({\"source\": valid_src, \"target\": valid_dst, \"split\": \"valid\"})\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "full_df = pd.concat([train_df, test_df, valid_df], ignore_index=True)\n",
    "\n",
    "# Print the length of the DataFrame before and after dropping duplicates\n",
    "print(\"Before dropping duplicates:\", len(full_df))\n",
    "full_df = full_df.drop_duplicates()\n",
    "print(\"After dropping duplicates:\", len(full_df))\n",
    "\n",
    "# Print the cleaned DataFrame\n",
    "print(full_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 297753 entries, 0 to 297752\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   source  297753 non-null  object\n",
      " 1   target  297753 non-null  object\n",
      " 2   split   297753 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>297753</td>\n",
       "      <td>297753</td>\n",
       "      <td>297753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>238593</td>\n",
       "      <td>238054</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>-- -RRB-\\n</td>\n",
       "      <td>References\\n</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>146</td>\n",
       "      <td>1529</td>\n",
       "      <td>296402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            source        target   split\n",
       "count       297753        297753  297753\n",
       "unique      238593        238054       3\n",
       "top     -- -RRB-\\n  References\\n   train\n",
       "freq           146          1529  296402"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       source  \\\n",
      "1070       Oakland Athletics -LRB- -- -RRB-\\n   \n",
      "1198          St. Louis Rams -LRB- -- -RRB-\\n   \n",
      "1913                               -- -RRB-\\n   \n",
      "2010                               -- -RRB-\\n   \n",
      "3220    Arizona Diamondbacks -LRB- -- -RRB-\\n   \n",
      "...                                       ...   \n",
      "282487                             -- -RRB-\\n   \n",
      "285351                             -- -RRB-\\n   \n",
      "288891                             -- -RRB-\\n   \n",
      "293351                             -- -RRB-\\n   \n",
      "294487                             -- -RRB-\\n   \n",
      "\n",
      "                                                   target  split  \n",
      "1070    He plays right fielder\\/First baseman for the ...  train  \n",
      "1198               St. Louis Rams -LRB- 2001-2009 -RRB-\\n  train  \n",
      "1913    Pierre de Fermat makes a marginal claim to hav...  train  \n",
      "2010    February 3 - Tulip mania collapses in the Unit...  train  \n",
      "3220    Selected for the All-Star game x5 in 1999 , 20...  train  \n",
      "...                                                   ...    ...  \n",
      "282487  February 25 - Giovanni Battista Morgagni , Ita...  train  \n",
      "285351  2001 Hamilton-Wentworth Region and all six of ...  train  \n",
      "288891  January 1 - Russia first starts using Western ...  train  \n",
      "293351  October 1 - James Lawrence , U.S. Navy officer...  train  \n",
      "294487    January 2 - Amadeus I becomes King of Spain .\\n  train  \n",
      "\n",
      "[189 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "filtered_df = full_df[full_df['source'].str.contains(\"-- -RRB-\\\\n\", na=False)]\n",
    "\n",
    "# Print the filtered rows\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
